{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["QS0kHZfF6qj7","2RppCF6z6l7V","Sq4_4yi960To","2xeRjjST7XTf","dnAr8RQk7jzF"],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOX9qoNDyQ1CVlqmGIwqDy7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["https://www.kaggle.com/datasets/prasoonkottarathil/face-mask-lite-dataset"],"metadata":{"id":"QDYcq-Eh3oc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install opendatasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJoEzRr33p32","executionInfo":{"status":"ok","timestamp":1720115545808,"user_tz":-300,"elapsed":6372,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}},"outputId":"56d4a6a1-7436-4e5f-b64e-be7eb77aa0d4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.6.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}]},{"cell_type":"code","source":["import opendatasets as od\n","\n","od.download(\"https://www.kaggle.com/datasets/prasoonkottarathil/face-mask-lite-dataset\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTUQrQn33-bs","executionInfo":{"status":"ok","timestamp":1720117276430,"user_tz":-300,"elapsed":1588748,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}},"outputId":"94a85ac6-481a-41c6-9cfe-fee270e2da34"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: syedosamaalishah092\n","Your Kaggle Key: ··········\n","Dataset URL: https://www.kaggle.com/datasets/prasoonkottarathil/face-mask-lite-dataset\n","Downloading face-mask-lite-dataset.zip to ./face-mask-lite-dataset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23.3G/23.3G [23:46<00:00, 17.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","from keras import layers\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from tqdm import tqdm\n","import re\n","from keras.preprocessing.image import img_to_array"],"metadata":{"id":"Pi8k3aTx4inO","executionInfo":{"status":"ok","timestamp":1720120978870,"user_tz":-300,"elapsed":4221,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# to get the files in proper order\n","def sorted_alphanumeric(data):\n","    convert = lambda text: int(text) if text.isdigit() else text.lower()\n","    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","    return sorted(data,key = alphanum_key)\n","# defining the size of the image\n","SIZE = 128\n","_img = []\n","path = '/content/face-mask-lite-dataset/without_mask'\n","files = os.listdir(path)\n","files = sorted_alphanumeric(files)\n","for i in tqdm(files):\n","        if i == 'seed9090.png':\n","            break\n","        else:\n","            img = cv2.imread(path + '/'+i,1)\n","            # open cv reads images in BGR format so we have to convert it to RGB\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            #resizing image\n","            img = cv2.resize(img, (SIZE, SIZE))\n","            img = (img - 127.5) / 127.5\n","            imh = img.astype(float)\n","            _img.append(img_to_array(img))"],"metadata":{"id":"mZObfT7Q4uOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_images(sqr = 5):\n","    plt.figure(figsize = (10,10))\n","    plt.title(\"Real Images\",fontsize = 35)\n","    for i in range(sqr * sqr):\n","        plt.subplot(sqr,sqr,i+1)\n","        plt.imshow(_img[i]*0.5 + 0.5 )\n","        plt.xticks([])\n","        plt.yticks([])\n","\n","# to plot images\n","plot_images(6)"],"metadata":{"id":"0GYHTD2f5FBS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","dataset=tf.data.Dataset.from_tensor_slices(np.array(_img)).batch(batch_size)"],"metadata":{"id":"UxcwzwFr549l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Generator**"],"metadata":{"id":"QS0kHZfF6qj7"}},{"cell_type":"code","source":["latent_dim = 100\n","def Generator():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(128*128*3, use_bias=False, input_shape=(latent_dim,)))\n","    model.add(layers.Reshape((128,128,3)))\n","    # downsampling\n","    model.add(tf.keras.layers.Conv2D(128,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2D(256,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","\n","    model.add(tf.keras.layers.LeakyReLU())\n","    #upsampling\n","    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","\n","    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Conv2DTranspose(3,4,strides = 1, padding = 'same',activation = 'tanh'))\n","\n","\n","\n","    return model"],"metadata":{"id":"S68T0cj4559J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator = Generator()\n","generator.summary()"],"metadata":{"id":"68ombWyi6SGs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Discriminator**"],"metadata":{"id":"2RppCF6z6l7V"}},{"cell_type":"code","source":["def Discriminator():\n","    model = tf.keras.models.Sequential()\n","    model.add(tf.keras.layers.Input((SIZE, SIZE, 3)))\n","    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n","    model.add(tf.keras.layers.LeakyReLU())\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))\n","    return model\n",""],"metadata":{"id":"5h-0GwTa6THz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator = Discriminator()\n","discriminator.summary()"],"metadata":{"id":"RT_gGjiC6iQm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["noise = np.random.normal(-1,1,(1,100))\n","img = generator(noise)\n","plt.imshow(img[0,:,:,0])\n","plt.show()"],"metadata":{"id":"nFQn3loO6uye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"Sq4_4yi960To"}},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.RMSprop(\n","        lr=.0001,\n","        clipvalue=1.0,\n","        decay=1e-8\n","    )\n","cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"],"metadata":{"id":"iw6Bko0A6zT3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output),fake_output)\n","def discriminator_loss(fake_output, real_output):\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n","    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n","    return fake_loss + real_loss"],"metadata":{"id":"6fdm2dL667Tu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_steps(images):\n","    noise = np.random.normal(0,1,(batch_size,latent_dim))\n","    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\n","        generated_images = generator(noise)\n","        fake_output = discriminator(generated_images)\n","        real_output = discriminator(images)\n","\n","        gen_loss = generator_loss(fake_output)\n","        dis_loss = discriminator_loss(fake_output, real_output)\n","\n","\n","    gradient_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradient_of_discriminator = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n","\n","    optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n","    optimizer.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))\n","\n","    loss = {'gen loss':gen_loss,\n","           'disc loss': dis_loss}\n","    return loss"],"metadata":{"id":"Yo0YNkO269_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_generated_images(square = 5, epochs = 0):\n","\n","\n","  plt.figure(figsize = (10,10))\n","  for i in range(square * square):\n","    if epochs != 0:\n","        if(i == square //2):\n","            plt.title(\"Generated Image at Epoch:{}\\n\".format(epochs), fontsize = 32, color = 'black')\n","    plt.subplot(square, square, i+1)\n","    noise = np.random.normal(0,1,(1,latent_dim))\n","    img = generator(noise)\n","    plt.imshow(np.clip((img[0,...]+1)/2, 0, 1))\n","\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid()"],"metadata":{"id":"tC5Nx7f27Dvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","def train(epochs,dataset):\n","\n","    for epoch in range(epochs):\n","        start = time.time()\n","        print(\"\\nEpoch : {}\".format(epoch + 1))\n","        for images in dataset:\n","            loss = train_steps(images)\n","        print(\" Time:{}\".format(np.round(time.time() - start),2))\n","        print(\"Generator Loss: {} Discriminator Loss: {}\".format(loss['gen loss'],loss['disc loss']))"],"metadata":{"id":"a4lnbDAR7MkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(5,dataset)"],"metadata":{"id":"ekgbXmXS7P8F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Evaluation**"],"metadata":{"id":"2xeRjjST7XTf"}},{"cell_type":"code","source":["plot_generated_images(1)"],"metadata":{"id":"dTPsLWJj7TXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_generated_images(2)"],"metadata":{"id":"_A0nZLT87biV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_generated_images(5)"],"metadata":{"id":"pFZb9drS7cjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_generated_images(7)"],"metadata":{"id":"1n6H7t2j7gs3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Save the Model**"],"metadata":{"id":"dnAr8RQk7jzF"}},{"cell_type":"code","source":["generator.save('generator.h5')\n","discriminator.save(\"discriminator.h5\")"],"metadata":{"id":"-eHc4-GN7jXX"},"execution_count":null,"outputs":[]}]}